项目架构设计与重构方案
背景与目标
赛博炼丹项目旨在通过药童智能体从知识库中提取多条笔记信息，并将其“炼制”成洞见丹丸（insight pill）供用户使用。目前的Pipeline仍以“逐对笔记链接”的方式生成洞见，这种线性处理模式在复杂任务下存在局限[1]。为提升洞见质量和系统灵活性，我们计划引入Ultra RAG（超检索增强生成）的核心思想，采用Agent优先的模块化架构。目标是让药童作为核心智能体，根据用户指示和配方（丹方）自主规划步骤，调用工具（如笔记检索、知识图谱构建、LLM生成等），生成综合多源信息的洞见。这种设计将使系统具备更强的扩展性、可维护性，并便于未来集成新的技术。
核心架构设计
我们推荐采用模块化+Agent优先的架构，以药童Agent为中心协调各功能组件。架构主要包含以下部分：
* 药童核心Agent（YaoTong Agent）：扮演“炼丹师”角色，负责解析用户请求、读取丹方配置，规划执行步骤。它通过维护对话上下文（类似Claude等大模型的长上下文记忆）来跟踪用户指示、历史洞见等信息，确保连续对话的一致性。Agent根据任务需要调用外部工具完成具体操作[2]。这种Agent驱动的设计是当前灵活AI产品的趋势[3]，可支持复杂的多步骤推理和工具调用[1]。
* Planner（规划器）：药童内部或独立的规划模块。它根据用户问题和丹方，在调用LLM推理或预定义规则下，生成解决任务的计划。例如，Planner可能会决定先检索相关笔记、再构建关联图、最后调用LLM汇总。相比ReAct逐步反应式Agent，显式的整体规划有助于Agent全局考虑任务，提高效率和结果质量[4]。LangChain的Plan-and-Execute代理模式证明了先规划后执行能带来更快更优的多工具调用[5][6]。
* 工具模块（Tools）：可扩展的独立功能组件，Agent根据需要调用它们完成子任务。初始的关键工具包括：
* 笔记检索模块：从知识库中检索相关笔记内容。可使用关键词搜索或向量数据库匹配，实现语义级查找。RAG的第一步就是获取相关资料[7]。建议封装一个retrieve_notes(query, k)函数或类，将用户查询（或经Agent修正的查询）发送到笔记库，返回前k条相关笔记文本片段。
* 知识图谱/关系分析模块（可选）：根据检索到的笔记，构建它们之间的关系图（例如主题关联、引用关系）。若丹方要求use_graph=true，则Agent调用此模块。它可以输出一个结构化的图数据（节点代表笔记/概念，边代表关联）。这个图谱有助于Agent识别信息交叉点或主题脉络，为洞见生成提供更深层关系。即使不直接用于LLM输入，图数据可用于可视化（如脑图canvas）或供用户交互探索。
* 洞见生成模块：调用大型语言模型（如GPT-4/Claude等）将检索到的多条笔记内容融合，生成最终洞见回答。与传统逐对链接不同，我们将所有相关信息混合作为LLM输入，由其综合分析后给出洞见。这相当于多文档总结/问答[8]――LLM从一组文档中提取并融合洞见[8]。为了实现此功能，可设计一个generate_insight(notes_list, prompt_instruction)函数：构建提示模板，包含用户问题、提取的主要笔记内容（或其要点），并要求LLM输出凝练且有依据的洞见。必要时，Prompt里可以引导模型给出更深层次的分析或启发式见解，以体现“炼丹”后的独特价值。
* MCP模块：如果现有代码里有“MCP”工具，可将其视为类似于上述工具的一个组件。根据上下文推测，MCP可能负责内存管理或计划执行控制。如果保留，该模块由Agent按需调用，例如让MCP辅助决策或管理长文本分段。
* 内存与上下文维护：药童Agent需要维护对话与知识记忆，包括：
* 长期记忆：存储历史交互产生的洞见pill，以及用户提供的背景偏好等。可以将每次洞见结果存入一个缓存（例如列表或向量DB），以便后续查询或深入挖掘时检索引用。
* 工作记忆：当前对话的上下文，在与用户交互过程中持续提供给LLM。由于我们希望允许用户在已有洞见pill基础上深入对话，Agent应能将先前相关洞见内容纳入新一轮提示，形成 “在先洞见之上继续炼丹” 的效果。这类似于AI助手的聊天记忆，但我们的Agent可在提示中强调先前洞见的要点或局限，从而引导模型深化或扩展洞见。
* 多模态支持（未来扩展）：对于canvas脑图等交互形式，Agent需要维护额外的结构化上下文，例如当前脑图节点信息、用户在图上点选的位置等，以便相应调整输出格式或内容。
以上核心组件通过模块化接口集成在一起。药童Agent通过调用这些模块的方法完成任务。由于各模块分工明确、接口清晰，未来可以轻松替换或新增模块（例如用不同向量数据库替换检索模块，实现横向扩展）。整个系统以Agent决策为中心，松耦合模块为支撑，符合“Modular, Agent-first, Scalable, Easy-to-update”的设计理念。
丹方（Recipe）配置设计
丹方相当于一种任务配置/策略，用于告诉药童本次炼丹应采用何种力度和手法。用户指令确定了“炼什么丹”（想要什么洞见），而丹方规定“怎么炼”。设计丹方机制时，可以参考Prompt模板或Pipeline配置的概念，将其实现为易于扩展的配置结构：
* 配置内容：根据需求，丹方可以包含如下参数：
* notes_limit（笔记提取数量）：本次最多提取多少条笔记作为原料。例如快速模式可能提取3条，深度模式提取10条。
* explore_depth（探索深度）：是否进行多跳检索的深度。深度=1表示只检索与用户问题直接相关的笔记；深度=2则在第一批笔记的引用或关联笔记中进一步检索补充信息。以此类推，多层次递归拓展相关知识网络，获取更全面的信息。
* use_graph（是否构建知识图谱）：布尔值或模式枚举。true则启用知识图谱模块，将检索结果关联成网络；false则跳过图谱构建直接汇总。
* 其他可能参数：如summary_style（洞见呈现风格：简短结论 vs 详细分析）、model（指定LLM模型类型，如GPT4或Claude2）、citing（是否输出来源引用）等等。设计时预留这些字段，方便将来扩展配置项。
* 实现方式：可以采用数据类/字典定义丹方。例如创建一个名为Recipe的数据类：
  class Recipe:
    def __init__(self, notes_limit=5, explore_depth=1, use_graph=False):
        self.notes_limit = notes_limit
        self.explore_depth = explore_depth
        self.use_graph = use_graph
        # ...其他参数
  这样可以轻松实例化不同配方，如quick_recipe = Recipe(notes_limit=3, explore_depth=1, use_graph=False)或deep_recipe = Recipe(notes_limit=10, explore_depth=2, use_graph=True)。也可以用简单的dict来存储这些参数，根据需要传递给各模块使用。
另一种做法是使用预置模板：维护一个配置文件或字典映射，定义若干命名的配方（类似于“单方”、“复方”）。例如：
RECIPE_PRESETS = {
    "quick": {"notes_limit": 3, "explore_depth": 1, "use_graph": False},
    "comprehensive": {"notes_limit": 8, "explore_depth": 2, "use_graph": True}
}
用户可以选择预置名字，或通过界面滑杆/选项勾选来定制配方参数。推荐使用结构化的数据格式（如JSON/YAML）存储这些配方，方便日后修改和自动加载。
* 配方解析与应用：药童Agent接受用户请求时，也会拿到一个Recipe对象（或默认配置）。Agent的Planner和各工具模块都应参考这个配方。例如：
* 检索模块用notes_limit决定返回多少结果；如果explore_depth>1，则在检索到的笔记中提取出关键实体或链接，再递归调用检索扩展。
* 如果use_graph=True，Agent在检索完成后调用图谱模块，将笔记关系结构化，并可能将此结构简要纳入LLM提示（提示模型关注几个主要关联）。
* 洞见生成时，可以根据不同配方调整提示语气和详略程度（例如comprehensive配方下要求模型输出详细、引用充分的洞见）。
通过丹方机制，我们实现了策略与执行解耦：无需修改代码逻辑即可通过不同配方调控系统行为。例如，当需要快速回应时用精简配方，当需要深度研究时用深入配方。这种配置方法类似于在机器学习pipeline中切换不同参数集，易于理解和借鉴。在我们的设计理念下，丹方提供了一种优雅的控制系统行为的手段，使得药童既能遵循用户高层意图，又能灵活调整内部流程。您可以参考一些开源项目中对问答链配置的做法，例如LLamaIndex的Composable Graph将多文档检索、总结组合成不同查询模式[9]，这与我们的“配方”概念有异曲同工之妙。
连续对话与增强交互设计
正如您指出的，我们希望用户在拿到某个洞见pill后，能够继续与Agent就此深入对话、探索细节。这部分相当于在传统ChatGPT对话功能基础上，结合我们的洞见生成特色，提供更富上下文和多形式的交互。设计要点如下：
* 对话上下文承接：每个洞见pill产生后，药童Agent应将其内容摘要或全文存入上下文。后续用户的提问若与之前洞见相关，Agent的提示会包含该洞见的重要内容[10]。例如： 用户：“这颗洞见丸提到的假设背后有什么依据？” ―― Agent会检索先前洞见丸中涉及的论据来源，或者直接在提示中引用先前的关键点，让LLM基于已有内容进一步解释。这实现了基于洞见的连续知识深化。
* 深入洞见的提示策略：为区别于一般闲聊，我们可以在Prompt设计上做文章，鼓励Agent提供更深层次的分析。例如，在每轮对话中追加隐式指令：“结合已有洞见和新的资料，挖掘更深层的原理、影响或方案。” 这样LLM会倾向于产出更有洞见（insightful）的回复，而非仅仅重复已知内容。我们也可引入自我反省步骤（类似Chain-of-Thought的思考）让Agent检查当前洞见是否有待补充之处，再决定下一步行动。
* 动态检索与记忆：在对话扩展过程中，如果用户提出新的问题或要求更多细节，Agent可以再次调用检索模块补充新的信息。这时可以结合已有知识图谱或已知线索，提高检索的针对性。例如利用先前洞见中的人名地名作为关键词，获取更详细资料。Agent在多轮对话中应灵活构建查询――这正是Agent相比静态系统的优势。
* 多模态呈现的可能：为提高交互体验，我们考虑引入脑图（思维导图）或Canvas画布来呈现洞见及其关联知识。这需要架构支持以下几点：
* 结构化输出：除文本洞见外，Agent还可以输出结构数据描述知识节点及关系。例如返回一个JSON，列出洞见中的关键点及其联系，用于前端渲染思维导图。
* 模式切换：Agent需识别何时用户想要可视化。例如用户请求“生成脑图”或配方里指定某种可视化模式，则Agent调用特殊的渲染模块或以不同Prompt引导LLM输出符号标记的结构，让前端识别转化为图形。
* 持续互动：在Canvas上用户点击某节点提出问题，系统应将该节点作为新的上下文重点。Agent获取该节点对应的知识（可以从图谱模块的结构中找到相应笔记内容），然后类似主线对话那样回答。这要求Agent维护一份共享的知识图谱/节点索引，以便快速定位并应用用户在可视化界面上的交互。
目前，实现脑图交互可能超出当前重构范围，但值得在架构上预留接口。例如知识图谱模块输出结果既用于LLM提示也返回前端。如果短期不做前端，也可让Agent用ASCII树或图结构语言（如Mermaid格式）输出一个简易脑图，以验证概念。
总之，在对话续拓方面，我们希望保持对话的线程连贯，充分利用先前产出的洞见，并通过更智能的提示和结构化思维使后续交互产生“渐入佳境”的效果，越聊洞见越深刻。相比普通问答机器人，我们的Agent因为有配方指导和丰富工具，可以提供一种仿佛和“研究助理”讨论的体验。
模块重构实施计划
针对以上架构设计，这里提供一个循序渐进的实施方案。重构过程将分阶段进行，每个阶段聚焦特定模块或功能的改进。您可以结合AI编程助手（如Cursor等）的力量，逐步完成以下任务。为方便与AI协作，每一步尽量原子、清晰，可独立验证。
阶段1：代码结构整理与模块定义
目标：梳理现有代码（synapse0.15-codex），划分出主要功能板块，并创建相应的模块/类框架。 1. 阅读现有代码：首先通读当前Pipeline相关的代码文件，定位笔记读取、处理、洞见生成等逻辑所在的位置。记录现有函数或类，例如是否有一个main()或类似pair_notes()函数负责主流程。找到“MCP”出现的地方，以明确其作用。 2. 模块划分：根据阅读结果，确定需要的模块。预计至少包括：Agent（主控）、Retrieval（检索）、InsightGenerator（洞见生成）、GraphBuilder（图谱，可暂时空实现）、Recipe（配置）。在代码中为每个模块创建独立的文件/类： - 新建 agent.py：定义YaoTongAgent类，包含属性如context_memory（对话历史）、方法如plan_and_execute(user_query, recipe). 先不填充细节，实现一个构造函数和占位方法。 - 新建 retrieval.py：定义NoteRetriever类或retrieve_notes函数。 - 新建 insight.py：定义InsightGenerator类或相关函数。 - 新建 graph.py：定义KnowledgeGraphBuilder类（哪怕里面先pass）。 - 新建 recipe.py：定义Recipe数据类用于配方配置。 - 将上述文件通过适当的__init__.py或主程序引用集成。 3. 接口设计：在每个模块中，先写出方法签名和docstring，明确输入输出。例如：
class NoteRetriever:
    def __init__(self, ...): ...
    def retrieve(self, query: str, k: int) -> List[Note]:
        """根据查询检索笔记库，返回相关笔记对象列表（或文本列表）"""
        ...
Note可以是自定义的数据结构（如包含标题、内容的对象）。
采用这种声明式写法，有助于您之后让AI根据函数注释来填充实现。
1. 确保模块独立可测试：为每个模块添加简单的测试用例或暂时的__main__块。例如在retrieval.py里写一个假测试：if __name__=="__main__": print(NoteRetriever().retrieve("test", k=1)). 当然目前没有数据库，可以返回空或假数据。这样重构的基本骨架就建立起来了。
与AI协作提示: “打开文件X，将其中的笔记处理逻辑移入Y类的method Z中。按照以下接口改写…”。让AI辅助重构时，先让它理解函数的目的，再一步步实现。保持一次只修改或创建一个文件的范围。
阶段2：实现笔记检索模块
目标：实现NoteRetriever，使其能够根据查询返回笔记内容，为洞见生成提供素材。
1. 设计笔记存储访问：确定笔记数据来源，例如Markdown/文本文件存储、本地数据库、向量索引等。如果已有现成的数据结构，沿用之。如果没有，考虑以向量检索提升语义匹配（例如使用FAISS、ChromaDB）。短期也可简单遍历文本进行关键词搜索。根据项目规模选择方案。 2. 实现NoteRetriever.retrieve： - 如果采用关键词全文检索：读取所有笔记文本，简单筛选包含关键词或使用TF-IDF排序。返回匹配度最高的k条。实现简单但效率不高，可暂用做原型。 - 如果采用向量检索：利用预训练模型将笔记向量化，查询时将问题向量与笔记向量进行最近邻搜索[11]。可以调用现有的embedding库和相似度计算库。此涉及较多外部依赖，可视情况简化为假接口或留待后续实现。
为了模块化，您可以将embedding或索引操作封装到NoteRetriever内部，或者进一步细分一个VectorIndex类来管理。 3. 支持多步检索：考虑explore_depth参数。如果depth>1，在初次检索结果基础上执行拓展： - 提取每条结果中的重要实体（人名、术语等）或引用的其他笔记ID； - 对这些新线索再次调用retrieve（depth-1递归），获取更多关联笔记； - 合并所有结果（注意去重）。
这一部分可以先留空，或实现一个简单版本，例如仅根据第一轮结果的标题再次检索标题相似的笔记。 4. 测试检索模块：编写简单测试，模拟几条虚拟笔记数据，测试检索函数输出是否符合预期格式。若已有笔记样本，更好――例如调用retrieve("丹方", k=3)看看输出。
与AI协作提示: “请实现NoteRetriever.retrieve方法，使其返回包含查询字符串的文本段落。使用Python的re或简单字符串查找即可”。一步步增加复杂性，例如先实现基本检索，再引导AI增加depth逻辑。
阶段3：整合Recipe配置机制
目标：让Agent能够接受并使用配方参数，驱动不同的执行流程。
1. Recipe类完善：根据之前定义的Recipe数据类，补充可能需要的方法。例如一个to_dict()方便打印，或者在Agent中直接使用其属性。 2. Agent使用Recipe：在YaoTongAgent.plan_and_execute(user_query, recipe)中，实现读取配方并影响执行流程的大致逻辑： - 根据 recipe.notes_limit 设置检索数量k，并调用NoteRetriever检索主查询。 - 根据 recipe.explore_depth 决定是否进行额外深度的检索（如果实现了的话）。 - 如果 recipe.use_graph 为真，调用GraphBuilder构建关系图（现阶段或可返回简单结构如{"nodes": [...], "edges": [...]}）。 - 将得到的笔记集合传递给InsightGenerator以生成回答。 - 返回洞见结果（和可选的图结构等）。 此处先写伪代码/日志，比如：
notes = note_retriever.retrieve(query, k=recipe.notes_limit)
if recipe.explore_depth > 1:
    # 深度检索拓展（待实现）
    notes = expand_notes(notes, depth=recipe.explore_depth)
if recipe.use_graph:
    graph = graph_builder.build(notes)
insight = insight_generator.summarize(query, notes)
return insight, graph
先不深入实现细节，让代码能够跑通返回一个基本结果（比如insight先返回拼接的笔记内容或固定句子）。这样搭好流程框架，后续再逐一填充功能。 3. 默认配方：实现如果用户不提供Recipe，则使用默认配置。可以在Agent内部定义一个default_recipe = Recipe()或者在解析用户输入时赋默认值。确保所有调用Agent的地方都有配方参数可用（哪怕是默认）。
与AI协作提示: 引导AI按照我们的人类伪代码翻译成实际代码。例如_“在YaoTongAgent.plan_and_execute中，根据Recipe内容调用检索和生成模块。按照以下逻辑编写...”_。由于我们已经用清晰的步骤写出逻辑，AI应能顺利转换成代码。
阶段4：实现洞见生成模块
目标：利用LLM将笔记混合生成洞见文本，实现InsightGenerator模块核心功能。
1. 设计Prompt模板：确定向LLM提问的格式。通常包括：用户问题、整合的笔记信息、任务指令。例如：
用户提问: <user_query>  
已知信息:  
1. <笔记1摘要/内容>  
2. <笔记2摘要/内容>  
...  
请根据以上信息，给出凝练的回答，并尽量提供新的见解。
模板文字可以写在代码里，也可以放在单独的配置文件，方便日后调整。注意:如果笔记内容很长，需要截取要点或先用模型对每条笔记生成要点摘要，以保证总提示不超长。 2. 调用LLM API：使用OpenAI API、Anthropic API或本地模型接口来获取生成。可以先封装一个LLMClient类，实现complete(prompt)调用远程接口。为了防止一开始集成API的复杂性，也可以模拟LLM返回，用简单的字符串拼接或规则生成假输出做测试。等整体联调时再替换为实际API调用。 3. InsightGenerator.summarize 实现： - 输入：用户query、笔记列表（以及可选的图谱/上下文）。 - 构造Prompt：按上述模板填充内容。可以对每条笔记做一下截断或提取标题+摘要。 - 调用LLMClient获取回复。如果未集成API，则暂时组合笔记文本作为输出（如：返回 "根据笔记A和B，可以得出...【模拟洞见】"）。 - 返回洞见字符串（未来可扩展为富文本或带来源标注的格式）。 4. 测试洞见生成：用少量示例笔记，调用InsightGenerator看看输出。若使用真实模型，在测试环境用小模型或API调用次数受限的模型验证效果。 5. 完善洞见质量（可选）：如果希望洞见更有依据或引用，可以考虑在Prompt中要求模型按照某种格式输出（比如每句话附来源编号），甚至可以让它输出一个JSON结构包含观点和对应笔记id。这部分可作为改进方向，在基本功能跑通后再尝试。
与AI协作提示: 可以让AI协助编写Prompt模版字符串。例如_“编写一个函数compose_prompt(notes, query) 将若干笔记内容融入提示，要求输出格式如...”。_ 之后让AI使用OpenAI库（如openai.Completion）代码示例。但注意API密钥等敏感信息别硬编码。
阶段5：集成与基本联调
目标：将前面各模块连接起来，在一次完整调用中执行用户请求，得到洞见输出。
1. 主流程：可能已有一个主脚本或接口函数。例如def answer_question(query)或命令行接口。现在用Agent替换旧逻辑：
agent = YaoTongAgent(...)
recipe = Recipe(...)  # 可以选用预置
insight, graph = agent.plan_and_execute(user_query, recipe)
print("洞见输出:", insight)
如果之前Pipeline是线性的，注意删除旧的临时变量或步骤，只保留Agent调用。确保异常处理，如检索不到笔记时给出提示，LLM未返回时重试等基础健壮性。 2. 测试完整流程：模拟几个查询场景： - 常规问题（知识库中能找到直接答案的）； - 需要综合多条笔记的深度问题； - 配方不同参数的情景（如快速模式 vs 深入模式）。
查看控制台或日志，确认Agent按照预期调用了模块，顺序正确。洞见结果是否合理（哪怕现在是stub，也要结构上正确）。逐步修正集成bug，比如变量未定义、类型不匹配等。 3. 日志和可观察性：为便于调试和后续优化，在各关键步骤加入日志输出。例如Agent在规划时打印使用的配方，检索模块打印找到了哪些笔记标题，图谱模块打印节点数，LLM输出前打印提示长度等。这在开发中非常重要，后期可以换成日志框架按需启用。
与AI协作提示: 如果集成出现错误，可以把错误信息贴给AI，让它协助分析修改。基本联调通常需要来回几次调试，逐个解决问题。确保每次修改控制在单一模块范围内，让AI专注于该处即可。
阶段6：扩展功能实现
目标：在基础功能跑通后，逐步实现更高级的特性：深度检索、知识图谱、对话记忆等。每项功能可单独一个小循环实现调试。
1. 实现深度检索：完善阶段2中NoteRetriever的explore_depth逻辑。可以借助AI自然语言处理库提取关键词。或者更简单地，取初始结果的标题/索引，再在所有笔记中搜索这些标题出现的段落，作为延伸笔记。例如：
  if depth > 1:
    for note in initial_results:
        for link in note.links:  # 假设每个笔记对象有links属性
            extra_notes += retrieve(link, k=1)
    results += extra_notes
  注意避免死循环或爆炸，可限制总笔记数不超过某上限。完成后，编写测试验证给定depth=2时结果是否增加合理笔记。
2. 完善知识图谱模块：根据实际数据格式实现GraphBuilder。例如笔记有元数据指示关联（引用、标签等），则GraphBuilder遍历笔记列表构建节点和边；如果没有明确关系，可基于内容相似度或共同关键词建立简单关联。输出的Graph结构可以定义为:
  class KnowledgeGraph:
    nodes: List[str]  # 节点标识，比如笔记标题或ID
    edges: List[Tuple[str, str, str]]  # 三元组 (source, target, relation) 关系可用"related_to"等
  GraphBuilder.build(notes)返回这个Graph对象。并在Agent中将graph传递给InsightGenerator（或直接返回给上层，用于可视化）。测试可以打印graph.nodes/edges验证正确性。
3. 加强对话记忆：在Agent中引入会话历史记录机制：
4. 在YaoTongAgent中增加属性history = []，每次与用户交互（一次plan_and_execute完成后）将用户query和生成的insight保存为一条记录（可以存dict {"query": ..., "insight": ...}）。
5. 在下次调用plan_and_execute时，将history简要传递给LLM提示。例如InsightGenerator在构造prompt时，可以在开头附加：先前讨论: [上一次的问题和洞见简述]。需要注意控制长度，可以只取最近一条或几条记录概要。
6. 实现一个辅助函数get_recent_context()用于生成上述对话概要串。 测试方式：连续调用Agent两次模拟对话，第二次的问题看Agent是否利用了第一次的洞见（可以在日志中打印提示以确认）。
7. 洞见质量优化：尝试提升LLM生成洞见的可靠性和深度：
8. 在Prompt末尾明确要求新的见解或者行动建议等，以避免只是拼凑笔记内容。
9. 如果模型输出太长或无关信息，考虑在输出后再做一次后处理，例如用规则或再调用LLM总结精简。
10. 如果希望附带来源引用，可以在Prompt要求模型标注每段来源。需要LLM模型足够听懂并执行格式要求，调优这部分可能要多尝试。
每添加一个功能，都运行完整流程测试，确保不破坏之前功能。同时随时更新单元测试或示例，以覆盖新行为。
与AI协作提示: 针对每个小功能，可直接让AI实现细节。例如_“在NoteRetriever中增加depth参数支持，如depth>1则对每条结果的links再检索一次。”_ 并提供当前Note类结构让AI参考。一步步完成后运行，查看输出再调整。
阶段7：项目定型与展望
目标：整理文档和思考未来扩展点，确保项目易于维护和升级。 1. 代码文档与注释：为核心类和函数补充清晰的注释，解释其用途和算法。特别是Recipe配置、Agent规划逻辑等，方便未来自己或开源社区理解你的设计理念。可以在README中描述赛博炼丹架构总览，列出模块说明和使用方法。 2. 样例与单元测试：准备若干典型输入的示例，展示如何调用Agent生成洞见，以及如何切换配方。编写基本的单元测试，以自动检查重要功能是否正常（如检索模块给定伪数据能返回预期结果，InsightGenerator在mock下返回格式正确的字符串等）。 3. 性能与优化考虑：如果笔记库较大或模型调用开销高，思考优化方案，例如：引入缓存――对于重复问过的问题直接返回缓存洞见；异步并行――如果Graph和Insight生成可以并行则优化等待时间等。这些可以记在TODO或文档中。 4. 未来技术集成：展望可以“slap on”到项目的技术： - 更强的LLM：如后续使用更大上下文窗口的模型，直接将更多笔记投入提示，从而减少多轮检索需要。Claude等支持超长输入[12]可以让我们一次放入几十条笔记上下文。 - 多Agent协作：引入多个Agent分工，如一个Agent专门挖掘数据、另一个Agent整理汇总，模拟“讨论”产生洞见。Multi-Agent RAG已经被提出用于提升复杂任务表现[13][14]。可以尝试Agent之间用对话方式共享信息，让药童不再孤军奋战。 - 主动学习与反馈：让Agent从用户反馈中学习调整。例如用户评价某次洞见不准确，系统记录并下次检索时排除相关来源，或者Fine-tune一个小模型更适合你的笔记语料。 - UI交互：开发图形界面显示脑图、支持用户拖拽节点提问等。在架构上，我们已经支持输出graph数据，只需前端开发配合，即可提升用户体验。
完成重构后，整个项目将更加模块清晰、易于扩展。当有新技术出现时，比如更好的检索算法或新的代理范式，你可以定位到相应模块进行替换或添加，而不会影响其他部分功能。这正是我们通过模块化+Agent架构所获得的收益。
总结
通过以上设计和实施计划，我们将赛博炼丹项目升级为“Agent大脑 + 工具箱”的框架：药童Agent如同炼丹师，灵活调用各种工具，将海量笔记知识熔炼为洞见良方。整个系统具有高度的模块化和扩展性[2]，[1]。在重构过程中，建议充分利用AI助手来加速开发，但也要掌控节奏，逐步验证。每个阶段完成后，都将使项目朝着功能更强、结构更清晰迈进一步。按照此方案，相信赛博炼丹项目很快就能焕然一新，易于应对未来不断涌现的新技术和需求！
参考文献：
* LangChain官方博客：Plan-and-Execute Agents[2][5] C 介绍了计划-执行代理的架构优势。
* Shuyi Yang, 2025: MAS Is All You Need: Supercharge Your RAG with a Multi-Agent System[1][13] C 阐述了多智能体RAG系统相对于传统流水线在复杂交互任务中的优势。
* YData社区博客：Building a Multi-Document LLM App[8] C 展示了如何利用LLM从多文档集合中提炼洞见，与本项目多笔记融合思路类似。

[1] [7] [11] [13] [14] MAS is all you need: supercharge your RAG with a Multi-Agent System | TDS Archive
https://medium.com/data-science/mas-is-all-you-need-f61f6e6f3aad
[2] [3] [4] [5] [6] [10] Plan-and-Execute Agents
https://blog.langchain.com/planning-agents/
[8] [9] Building a Multi-Document Language Model App
https://ydata.ai/resources/multi-document-llm.html
[12] Introducing 100K Context Windows - Anthropic
https://www.anthropic.com/news/100k-context-windows
